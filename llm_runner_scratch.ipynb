{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /Users/shawnschulz/miniconda3/lib/python3.9/site-packages (2.0.0)\n",
      "Requirement already satisfied: typing-extensions in /Users/shawnschulz/miniconda3/lib/python3.9/site-packages (from torch) (4.4.0)\n",
      "Requirement already satisfied: filelock in /Users/shawnschulz/miniconda3/lib/python3.9/site-packages (from torch) (3.12.0)\n",
      "Requirement already satisfied: networkx in /Users/shawnschulz/miniconda3/lib/python3.9/site-packages (from torch) (2.8.8)\n",
      "Requirement already satisfied: jinja2 in /Users/shawnschulz/miniconda3/lib/python3.9/site-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: sympy in /Users/shawnschulz/miniconda3/lib/python3.9/site-packages (from torch) (1.11.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/shawnschulz/miniconda3/lib/python3.9/site-packages (from jinja2->torch) (2.1.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in /Users/shawnschulz/miniconda3/lib/python3.9/site-packages (from sympy->torch) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from transformers import pipeline\n",
    "from optparse import OptionParser\n",
    "#from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import os\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_path=\"/Users/shawnschulz/Downloads/01_test.json\"\n",
    "\n",
    "with open(json_path) as json_file:\n",
    "    schema_dictionary = json.load(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def schemaToDictionary(schemaList):\n",
    "    '''\n",
    "        Takes nodes or edges list and makes a dictionary you can index list elements using the ID, probably\n",
    "        only worth running this function if you have a really big graph you need to access nodes or edges of\n",
    "        many times, but this option is available for that\n",
    "    '''\n",
    "    newDict={}\n",
    "    for dictionary in schemaList:\n",
    "        newDict[dictionary['id']] = dictionary\n",
    "    return newDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findRoots(schema_dictionary):\n",
    "    '''\n",
    "        Finds the roots of a schema\n",
    "        1. Get all the ids of all nodes, put in a stack\n",
    "        2. Check what targets are currently in the schema\n",
    "        3. Remove them as you find them\n",
    "    '''\n",
    "    stack = []\n",
    "    for node in schema_dictionary['nodes']:\n",
    "        stack.append(node['id'])\n",
    "    for edge in schema_dictionary['edges']:\n",
    "        if edge['target'] in stack:\n",
    "            stack.remove(edge['target'])\n",
    "    return stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['00001']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "findRoots(schema_dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': 'e1-2', 'source': '1', 'target': '2'},\n",
       " {'source': '00001',\n",
       "  'sourceHandle': 'bottom',\n",
       "  'target': '3159559',\n",
       "  'targetHandle': 'top',\n",
       "  'id': 'reactflow__edge-00001bottom-3159559top'},\n",
       " {'source': '00001',\n",
       "  'sourceHandle': 'right',\n",
       "  'target': '3166128',\n",
       "  'targetHandle': 'left',\n",
       "  'id': 'reactflow__edge-00001right-3166128left'},\n",
       " {'source': '3166128',\n",
       "  'sourceHandle': 'bottom',\n",
       "  'target': '3171323',\n",
       "  'targetHandle': 'top',\n",
       "  'id': 'reactflow__edge-3166128bottom-3171323top'},\n",
       " {'source': '3159559',\n",
       "  'sourceHandle': 'right',\n",
       "  'target': '3171323',\n",
       "  'targetHandle': 'left',\n",
       "  'id': 'reactflow__edge-3159559right-3171323left'}]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "schema_dictionary['edges']\n",
    "#im pretty sure this flow was not made properly, to do the desired effect correctly can circumvent problem by closing loop from bottom to\n",
    "#top, but this might be very confusing for users who will expect source and target to not be dependent on which side but on\n",
    "#which node they drew the edge from, our first version will be side dependent but future versions should figure out on \n",
    "#client side where the edge started from and is going to source and target edges properly\n",
    "#there should also be some visual indication of where inputs and outputs are going, again just publish the website quickly and fix this\n",
    "#in an update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = schemaToDictionary(schema_dictionary['nodes'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': '00001',\n",
       " 'type': 'textInput',\n",
       " 'data': {'label': 'You are Frodo. Say something interesting, and respond to text above if you received any.'},\n",
       " 'position': {'x': 195.185336410498, 'y': 46.87644239300134},\n",
       " 'width': 289,\n",
       " 'height': 50,\n",
       " 'selected': False,\n",
       " 'positionAbsolute': {'x': 195.185336410498, 'y': 46.87644239300134},\n",
       " 'dragging': False}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test['00001']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to start with, I think we should always start from the first node created. May make sense in the future to allow user to specify\n",
    "#what node they want to start with, but i am too lazy to think of what the UX of that would be "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def runSchema(schema_dictionary):\n",
    "    '''\n",
    "        Take a schema and run the flow. \n",
    "        \n",
    "        Need a function that finds the root of the tree first.\n",
    "\n",
    "        Also needs a function to c\n",
    "\n",
    "        There are 2 things to track, what the current graph looks like and the stack of \n",
    "        nodes to run and their received prompts. Nodes on the stack have to check if they are a \n",
    "        root, or else they are not run yet. Root nodes on the stack are run in order, then\n",
    "        targets are added to the stack with their associated prompt. If the target is already\n",
    "        on the stack, simply give it the additional prompt.\n",
    "\n",
    "        If there are nodes, and all of the nodes have a source, this means that there is a loop \n",
    "        somewhere in the graph. We still want to run the flow, because recursive nodes are a \n",
    "        selling point. In this case, if ALL the nodes have a source, pick the most recently \n",
    "        created node and run it, sending its prompts and adding the new targets to the stack. We\n",
    "        do not update the graph now, instead simply running the node, then its targets in order.\n",
    "        This will continue running iterations, until a stop button is pressed.\n",
    "\n",
    "        The user will probably want to\n",
    "\n",
    "        We should create a stack, a list of dictionaries that look like this:\n",
    "        [{node_id: ____, sources_dict:{source_id:received_prompt = \"\" }}]\n",
    "        This forms a stack. Sources dict may or may not have multiple source_ids in it. Queue up\n",
    "        the next nodes to run based on what the targets of the node you just ran are. If\n",
    "        a node has multiple sources when it's run, combine those sources into one prompt\n",
    "        via concatenation. Received prompts are added first, with the LLMs actual text\n",
    "        entered into it added last. We may have to do prompt engineering to make sure\n",
    "        the LLM answers the prompt inputted into the box and not questions received as context,\n",
    "        but this is not preferred.\n",
    "        For bonus points, add an option to use dfs or bfs\n",
    "    '''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
