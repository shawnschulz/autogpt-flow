{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /Users/shawnschulz/miniconda3/lib/python3.9/site-packages (2.0.0)\n",
      "Requirement already satisfied: typing-extensions in /Users/shawnschulz/miniconda3/lib/python3.9/site-packages (from torch) (4.4.0)\n",
      "Requirement already satisfied: filelock in /Users/shawnschulz/miniconda3/lib/python3.9/site-packages (from torch) (3.12.0)\n",
      "Requirement already satisfied: networkx in /Users/shawnschulz/miniconda3/lib/python3.9/site-packages (from torch) (2.8.8)\n",
      "Requirement already satisfied: jinja2 in /Users/shawnschulz/miniconda3/lib/python3.9/site-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: sympy in /Users/shawnschulz/miniconda3/lib/python3.9/site-packages (from torch) (1.11.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/shawnschulz/miniconda3/lib/python3.9/site-packages (from jinja2->torch) (2.1.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in /Users/shawnschulz/miniconda3/lib/python3.9/site-packages (from sympy->torch) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from transformers import pipeline\n",
    "from optparse import OptionParser\n",
    "#from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import os\n",
    "import json\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_path=\"/Users/shawnschulz/Downloads/01_test2.json\"\n",
    "\n",
    "with open(json_path) as json_file:\n",
    "    schema_dictionary = json.load(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Should probably update this to use a python class, so that when we add new node types\n",
    "### we can reuse some methods without having to minor edits to make them compatible with\n",
    "### new node types. This is okay for now tho, since that will require thinking some new logic for\n",
    "### how the schema deals with sending outputs of nodes to nodes of different types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def schemaListToDictionary(schemaList):\n",
    "    '''\n",
    "        Takes nodes or edges list and makes a dictionary you can index list elements using the ID, probably\n",
    "        only worth running this function if you have a really big graph you need to access nodes or edges of\n",
    "        many times, but this option is available for that\n",
    "    '''\n",
    "    newDict={}\n",
    "    for dictionary in schemaList:\n",
    "        newDict[dictionary['id']] = dictionary.copy()\n",
    "    return newDict\n",
    "\n",
    "def hashedMappedSchemaDictionary(schema_dictionary):\n",
    "    '''\n",
    "        Take a whole schema dictionary and return a version that now has ID key'd nested dictionaries\n",
    "        rather than lists\n",
    "    '''\n",
    "    newDict={'nodes':{}, 'edges':{}}\n",
    "    nodesDict = schemaListToDictionary(schema_dictionary['nodes'])\n",
    "    edgesDict = schemaListToDictionary(schema_dictionary['edges'])\n",
    "    newDict['nodes'] = nodesDict\n",
    "    newDict['edges'] = edgesDict\n",
    "    return newDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findRoots(schema_dictionary):\n",
    "    '''\n",
    "        Finds the roots of a schema\n",
    "        1. Get all the ids of all nodes, put in a stack\n",
    "        2. Check what targets are currently in the schema\n",
    "        3. Remove them as you find them\n",
    "\n",
    "        Give schema dictionary (direct from json file), a dictionary\n",
    "        Returns the stack of roots of the tree, False if schema nodes have no sources\n",
    "    '''\n",
    "    stack = []\n",
    "    for node in schema_dictionary['nodes']:\n",
    "        stack.append(node['id'])\n",
    "    for edge in schema_dictionary['edges']:\n",
    "        if edge['target'] in stack:\n",
    "            stack.remove(edge['target'])\n",
    "    return stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def updateNodePrompts(node_prompt_dictionary, schema_dictionary):\n",
    "    '''\n",
    "        Takes a \n",
    "    '''\n",
    "    new_dictionary = schema_dictionary.copy()\n",
    "    for node in new_dictionary['nodes']:\n",
    "        if node['id'] in node_prompt_dictionary.keys():\n",
    "            old_prompt = node['data']['prompt'] \n",
    "            new_prompt = node_prompt_dictionary['id'] + ' \\n' + old_prompt\n",
    "            node['data']['prompt'] = new_prompt\n",
    "    return(new_dictionary)\n",
    "    \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def removeNodeIDs(id_list, schema_dictionary):\n",
    "    '''\n",
    "        Takes a list of id's to be removed and returns a new schema dictionary with the node\n",
    "        id's removed\n",
    "\n",
    "        Note, when making graph smaller, it will usually make more sense to remove unique\n",
    "        edge id's than nodes. However if there is some reason to this node removal function is here\n",
    "\n",
    "        This is also really slow, consider changing if u actually make graphs really big\n",
    "    '''\n",
    "    new_dictionary = schema_dictionary.copy()\n",
    "    for id in id_list:\n",
    "        for node in new_dictionary['nodes']:\n",
    "            if node['id'] == id:\n",
    "                new_dictionary['nodes'].remove(node)\n",
    "    return new_dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def removeEdgeIDs(id_list, schema_dictionary):\n",
    "    '''\n",
    "        takes a list of edge id's and returns a new schema dictionary with the edge id's removed\n",
    "        Note: important that you remove by edgeid, not source or target since the edge id is unique\n",
    "    '''\n",
    "    new_dictionary = schema_dictionary.copy()\n",
    "    for id in id_list:\n",
    "        for edge in new_dictionary['edges']:\n",
    "            if edge['id'] == id:\n",
    "                new_dictionary['edges'].remove(edge)\n",
    "    return new_dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to start with, I think we should always start from the first node created. May make sense in the future to allow user to specify\n",
    "#what node they want to start with, but i am too lazy to think of what the UX of that would be "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def runLLM(node_id, schema_dictionary):\n",
    "    '''\n",
    "        put a funciton that runs the LLM here\n",
    "    '''\n",
    "    #for testing just return a string to check that schema's working\n",
    "    return \"this is a test string\"\n",
    "\n",
    "    for node in schema_dictionary['nodes']:\n",
    "        if node['id'] == node_id:\n",
    "            prompt = ''\n",
    "            for key in node['data'].keys():\n",
    "                prompt += node['data'][key]\n",
    "                prompt += \" \\n\"\n",
    "            # run LLM on prompt, note that this output will need to be sent over web somehow\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def runSchema(schema_dictionary):\n",
    "    '''\n",
    "        Take a schema and run the flow. \n",
    "\n",
    "        There are 2 things to track, what the current graph looks like and the stack of \n",
    "        nodes to run and their received prompts. Nodes on the stack have to check if they are a \n",
    "        root, or else they are not run yet. Root nodes on the stack are run in order, then\n",
    "        targets are added to the stack with their associated prompt. If the target is already\n",
    "        on the stack, simply give it the additional prompt.\n",
    "\n",
    "        If there are nodes, and all of the nodes have a source, this means that there is a loop \n",
    "        somewhere in the graph. We still want to run the flow, because recursive nodes are a \n",
    "        selling point. In this case, if ALL the nodes have a source, pick the most recently \n",
    "        created node and run it, sending its prompts and adding the new targets to the stack. We\n",
    "        do not update the graph now, instead simply running the node, then its targets in order.\n",
    "        This will continue running iterations, until a stop button is pressed.\n",
    "\n",
    "        The user will probably want to\n",
    "\n",
    "        We should create a stack, a list of dictionaries that look like this:\n",
    "        [{node_id: ____, sources_dict:{source_id:received_prompt = \"\" }}]\n",
    "        This forms a stack. Sources dict may or may not have multiple source_ids in it. Queue up\n",
    "        the next nodes to run based on what the targets of the node you just ran are. If\n",
    "        a node has multiple sources when it's run, combine those sources into one prompt\n",
    "        via concatenation. Received prompts are added first, with the LLMs actual text\n",
    "        entered into it added last. We may have to do prompt engineering to make sure\n",
    "        the LLM answers the prompt inputted into the box and not questions received as context,\n",
    "        but this is not preferred.\n",
    "        For bonus points, add an option to use dfs or bfs\n",
    "    '''\n",
    "    ### Should listen here to see if user hit the pause/stop button, and if they did pause or stop the execution of the code\n",
    "\n",
    "    roots = findRoots(schema_dictionary)\n",
    "    \n",
    "    #Base case: Check if schema dictionary has no roots\n",
    "    if len(roots) == 0:\n",
    "        if not schema_dictionary['edges']:\n",
    "            sys.exit()\n",
    "        #If schema dictionary has no roots, check if empty. If empty, exit with some success code\n",
    "    \n",
    "        #if schema dictionary has no roots and is not empty, there is a loop. Listen for a stop\n",
    "        #signal from serverside, otherwise run schema dictionary in a loop \n",
    "\n",
    "    #Recursive case: Schema dictionary has roots. Get the outputs from the source node, make \n",
    "    #an updated schema dictionary where target nodes have the new outputs, and remove\n",
    "    #the edges that have already been checked\n",
    "\n",
    "    edge_ids_to_remove=[]\n",
    "    nodes_to_send_outputs={}\n",
    "    next_schema_dictionary=schema_dictionary.copy()\n",
    "    for root in roots:\n",
    "        for edge in next_schema_dictionary['edges']:\n",
    "            if edge['source'] == root:\n",
    "                edge_id = edge['id']\n",
    "                edge_ids_to_remove.append(edge_id)\n",
    "                nodes_to_send_outputs[edge['target']] = \"\"\n",
    "                print(nodes_to_send_outputs)\n",
    "                print(edge_ids_to_remove)\n",
    "        output = runLLM(root, next_schema_dictionary)\n",
    "        ### SEND OUTPUT TO CHATBOT TO OUTPUT HERE ####\n",
    "        for node_id in nodes_to_send_outputs.keys():\n",
    "            nodes_to_send_outputs[node_id] = output\n",
    "        updated_prompts_dict = updateNodePrompts(nodes_to_send_outputs, schema_dictionary)\n",
    "        next_schema_dictionary=removeEdgeIDs(edge_ids_to_remove, updated_prompts_dict)\n",
    "    print(next_schema_dictionary)\n",
    "    #runSchema(next_schema_dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'3159559': ''}\n",
      "['reactflow__edge-00001bottom-3159559top']\n",
      "{'3159559': '', '3166128': ''}\n",
      "['reactflow__edge-00001bottom-3159559top', 'reactflow__edge-00001right-3166128left']\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'prompt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[31], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m runSchema(schema_dictionary)\n",
      "Cell \u001b[0;32mIn[30], line 63\u001b[0m, in \u001b[0;36mrunSchema\u001b[0;34m(schema_dictionary)\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[39mfor\u001b[39;00m node_id \u001b[39min\u001b[39;00m nodes_to_send_outputs\u001b[39m.\u001b[39mkeys():\n\u001b[1;32m     62\u001b[0m         nodes_to_send_outputs[node_id] \u001b[39m=\u001b[39m output\n\u001b[0;32m---> 63\u001b[0m     updated_prompts_dict \u001b[39m=\u001b[39m updateNodePrompts(nodes_to_send_outputs, schema_dictionary)\n\u001b[1;32m     64\u001b[0m     next_schema_dictionary\u001b[39m=\u001b[39mremoveEdgeIDs(edge_ids_to_remove, updated_prompts_dict)\n\u001b[1;32m     65\u001b[0m \u001b[39mprint\u001b[39m(next_schema_dictionary)\n",
      "Cell \u001b[0;32mIn[25], line 8\u001b[0m, in \u001b[0;36mupdateNodePrompts\u001b[0;34m(node_prompt_dictionary, schema_dictionary)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[39mfor\u001b[39;00m node \u001b[39min\u001b[39;00m new_dictionary[\u001b[39m'\u001b[39m\u001b[39mnodes\u001b[39m\u001b[39m'\u001b[39m]:\n\u001b[1;32m      7\u001b[0m     \u001b[39mif\u001b[39;00m node[\u001b[39m'\u001b[39m\u001b[39mid\u001b[39m\u001b[39m'\u001b[39m] \u001b[39min\u001b[39;00m node_prompt_dictionary\u001b[39m.\u001b[39mkeys():\n\u001b[0;32m----> 8\u001b[0m         old_prompt \u001b[39m=\u001b[39m node[\u001b[39m'\u001b[39;49m\u001b[39mdata\u001b[39;49m\u001b[39m'\u001b[39;49m][\u001b[39m'\u001b[39;49m\u001b[39mprompt\u001b[39;49m\u001b[39m'\u001b[39;49m] \n\u001b[1;32m      9\u001b[0m         new_prompt \u001b[39m=\u001b[39m node_prompt_dictionary[\u001b[39m'\u001b[39m\u001b[39mid\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m+\u001b[39m \u001b[39m'\u001b[39m\u001b[39m \u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m'\u001b[39m \u001b[39m+\u001b[39m old_prompt\n\u001b[1;32m     10\u001b[0m         node[\u001b[39m'\u001b[39m\u001b[39mdata\u001b[39m\u001b[39m'\u001b[39m][\u001b[39m'\u001b[39m\u001b[39mprompt\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m new_prompt\n",
      "\u001b[0;31mKeyError\u001b[0m: 'prompt'"
     ]
    }
   ],
   "source": [
    "runSchema(schema_dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': 'e1-2', 'source': '1', 'target': '2'},\n",
       " {'source': '00001',\n",
       "  'sourceHandle': 'bottom',\n",
       "  'target': '3159559',\n",
       "  'targetHandle': 'top',\n",
       "  'id': 'reactflow__edge-00001bottom-3159559top'},\n",
       " {'source': '00001',\n",
       "  'sourceHandle': 'right',\n",
       "  'target': '3166128',\n",
       "  'targetHandle': 'left',\n",
       "  'id': 'reactflow__edge-00001right-3166128left'},\n",
       " {'source': '3166128',\n",
       "  'sourceHandle': 'bottom',\n",
       "  'target': '3171323',\n",
       "  'targetHandle': 'top',\n",
       "  'id': 'reactflow__edge-3166128bottom-3171323top'},\n",
       " {'source': '3159559',\n",
       "  'sourceHandle': 'right',\n",
       "  'target': '3171323',\n",
       "  'targetHandle': 'left',\n",
       "  'id': 'reactflow__edge-3159559right-3171323left'}]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "schema_dictionary['edges']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
