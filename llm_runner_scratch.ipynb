{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /Users/shawnschulz/miniconda3/lib/python3.9/site-packages (2.0.0)\n",
      "Requirement already satisfied: typing-extensions in /Users/shawnschulz/miniconda3/lib/python3.9/site-packages (from torch) (4.4.0)\n",
      "Requirement already satisfied: filelock in /Users/shawnschulz/miniconda3/lib/python3.9/site-packages (from torch) (3.12.0)\n",
      "Requirement already satisfied: networkx in /Users/shawnschulz/miniconda3/lib/python3.9/site-packages (from torch) (2.8.8)\n",
      "Requirement already satisfied: jinja2 in /Users/shawnschulz/miniconda3/lib/python3.9/site-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: sympy in /Users/shawnschulz/miniconda3/lib/python3.9/site-packages (from torch) (1.11.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/shawnschulz/miniconda3/lib/python3.9/site-packages (from jinja2->torch) (2.1.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in /Users/shawnschulz/miniconda3/lib/python3.9/site-packages (from sympy->torch) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from transformers import pipeline\n",
    "from optparse import OptionParser\n",
    "#from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import os\n",
    "import json\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_path=\"/Users/shawnschulz/Downloads/loop_test.json\"\n",
    "\n",
    "with open(json_path) as json_file:\n",
    "    schema_dictionary = json.load(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Should probably update this to use a python class, so that when we add new node types\n",
    "### we can reuse some methods without having to minor edits to make them compatible with\n",
    "### new node types. This is okay for now tho, since that will require thinking some new logic for\n",
    "### how the schema deals with sending outputs of nodes to nodes of different types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def schemaListToDictionary(schemaList):\n",
    "    '''\n",
    "        Takes nodes or edges list and makes a dictionary you can index list elements using the ID, probably\n",
    "        only worth running this function if you have a really big graph you need to access nodes or edges of\n",
    "        many times, but this option is available for that\n",
    "    '''\n",
    "    newDict={}\n",
    "    for dictionary in schemaList:\n",
    "        newDict[dictionary['id']] = dictionary.copy()\n",
    "    return newDict\n",
    "\n",
    "def hashedMappedSchemaDictionary(schema_dictionary):\n",
    "    '''\n",
    "        Take a whole schema dictionary and return a version that now has ID key'd nested dictionaries\n",
    "        rather than lists\n",
    "    '''\n",
    "    newDict={'nodes':{}, 'edges':{}}\n",
    "    nodesDict = schemaListToDictionary(schema_dictionary['nodes'])\n",
    "    edgesDict = schemaListToDictionary(schema_dictionary['edges'])\n",
    "    newDict['nodes'] = nodesDict\n",
    "    newDict['edges'] = edgesDict\n",
    "    return newDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'source': 'Greeter',\n",
       "  'sourceHandle': 'right',\n",
       "  'target': '7060395',\n",
       "  'targetHandle': 'left',\n",
       "  'id': 'reactflow__edge-Greeterright-7060395left'},\n",
       " {'source': 'Responder',\n",
       "  'sourceHandle': 'right',\n",
       "  'target': 'Audience 2',\n",
       "  'targetHandle': 'left',\n",
       "  'id': 'reactflow__edge-Responderright-Audience 2left'},\n",
       " {'source': 'Greeter',\n",
       "  'sourceHandle': 'right',\n",
       "  'target': 'Responder',\n",
       "  'targetHandle': 'left',\n",
       "  'id': 'reactflow__edge-Greeterright-Responderleft'},\n",
       " {'source': 'Responder',\n",
       "  'sourceHandle': 'right',\n",
       "  'target': 'Audience 1',\n",
       "  'targetHandle': 'left',\n",
       "  'id': 'reactflow__edge-Responderright-Audience 1left'}]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "schema_dictionary['edges']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "removing from stack\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Greeter']"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "findRoots(schema_dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findRoots(schema_dictionary):\n",
    "    '''\n",
    "        Finds the roots of a schema\n",
    "        1. Get all the ids of all nodes, put in a stack\n",
    "        2. Check what targets are currently in the schema\n",
    "        3. Remove them as you find them\n",
    "\n",
    "        Give schema dictionary (direct from json file), a dictionary\n",
    "        Returns the stack of roots of the tree, False if schema nodes have no sources\n",
    "    '''\n",
    "    stack = []\n",
    "    for edge in schema_dictionary['edges']:\n",
    "        if edge['source'] not in stack:\n",
    "            stack.append(edge['source'])\n",
    "    for edge in schema_dictionary['edges']:\n",
    "        if edge['target'] in stack:\n",
    "            print(\"removing from stack\")\n",
    "            stack.remove(edge['target'])\n",
    "    return stack\n",
    "\n",
    "def checkBranch(node_id, schema_dictionary):\n",
    "    '''\n",
    "        Check if a node ever results in a terminal branch\n",
    "    '''\n",
    "    for node in schema_dictionary['nodes']:\n",
    "        if node['id'] == node_id:\n",
    "            for edge in schema_dictionary['edges']:\n",
    "                if edge['source'] == node_id:\n",
    "                    return False\n",
    "                else:\n",
    "                    return True\n",
    "                \n",
    "def checkTerminal(node_id, schema_dictionary, seen = [], branch_dict = {}):\n",
    "    '''\n",
    "        Recursively checks if following a nodes targets results in a terminal branch\n",
    "    '''\n",
    "    targets = []\n",
    "    final_list = []\n",
    "    if node_id in seen:\n",
    "        branch_dict[node_id] = False\n",
    "        return branch_dict\n",
    "    for edge in schema_dictionary['edges']:\n",
    "        if edge['source'] == node_id:\n",
    "            seen.append(node_id)\n",
    "            targets.append(edge['target'])\n",
    "            branch_dict[node_id] = False\n",
    "        else:\n",
    "            branch_dict[node_id] = True\n",
    "            return branch_dict\n",
    "    if len(targets) == 0:\n",
    "        branch_dict[node_id] = True\n",
    "        return branch_dict\n",
    "    for target in targets:\n",
    "        final_list.append(checkTerminal(target, schema_dictionary, seen, branch_dict))\n",
    "        return(final_list)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Loop 1': True, 'Loop 2': True, 'Loop 3 ': True, '00001': True}"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkTerminal(\"00001\", schema_dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def updateNodePrompts(node_prompt_dictionary, schema_dictionary):\n",
    "    '''\n",
    "        Takes a \n",
    "    '''\n",
    "    new_dictionary = schema_dictionary.copy()\n",
    "    for node in new_dictionary['nodes']:\n",
    "        if node['id'] in node_prompt_dictionary.keys():\n",
    "            old_prompt = node['data']['prompt'] \n",
    "            new_prompt = node_prompt_dictionary[node['id']] + ' \\n' + old_prompt\n",
    "            node['data']['prompt'] = new_prompt\n",
    "    return(new_dictionary)\n",
    "    \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def removeNodeIDs(id_list, schema_dictionary):\n",
    "    '''\n",
    "        Takes a list of id's to be removed and returns a new schema dictionary with the node\n",
    "        id's removed\n",
    "\n",
    "        Note, when making graph smaller, it will usually make more sense to remove unique\n",
    "        edge id's than nodes. However if there is some reason to this node removal function is here\n",
    "\n",
    "        This is also really slow, consider changing if u actually make graphs really big\n",
    "    '''\n",
    "    new_dictionary = schema_dictionary.copy()\n",
    "    for id in id_list:\n",
    "        for node in new_dictionary['nodes']:\n",
    "            if node['id'] == id:\n",
    "                new_dictionary['nodes'].remove(node)\n",
    "    return new_dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def removeEdgeIDs(id_list, schema_dictionary):\n",
    "    '''\n",
    "        takes a list of edge id's and returns a new schema dictionary with the edge id's removed\n",
    "        Note: important that you remove by edgeid, not source or target since the edge id is unique\n",
    "    '''\n",
    "    new_dictionary = schema_dictionary.copy()\n",
    "    for id in id_list:\n",
    "        for edge in new_dictionary['edges']:\n",
    "            if edge['id'] == id:\n",
    "                new_dictionary['edges'].remove(edge)\n",
    "    return new_dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to start with, I think we should always start from the first node created. May make sense in the future to allow user to specify\n",
    "#what node they want to start with, but i am too lazy to think of what the UX of that would be "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def runLLM(node_id, schema_dictionary):\n",
    "    '''\n",
    "        put a funciton that runs the LLM here\n",
    "    '''\n",
    "    #for testing just return a string to check that schema's working\n",
    "    print(\"Running LLM\")\n",
    "    return \"this is a test string\"\n",
    "\n",
    "    for node in schema_dictionary['nodes']:\n",
    "        if node['id'] == node_id:\n",
    "            prompt = ''\n",
    "            for key in node['data'].keys():\n",
    "                prompt += node['data'][key]\n",
    "                prompt += \" \\n\"\n",
    "            # run LLM on prompt, note that this output will need to be sent over web somehow\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def outputToChatbot(output):\n",
    "    '''\n",
    "        Takes an output and sends it to the chatbot to be outputted\n",
    "    '''\n",
    "    print(\"Running outputToChatbot\")\n",
    "    return(\"Ready to send to output!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def listenForInput():\n",
    "    '''\n",
    "        Listens for an input from website if user pushes pause or stop\n",
    "    '''\n",
    "    print(\"Running listenForInput\")\n",
    "    return(\"Placeholder for listening to server!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def runSchema(schema_dictionary, next_node_in_loop = \"start\"):\n",
    "    '''\n",
    "        Take a schema and run the flow. Mutates schema dictionary and removes edges not part of a loop, edges within or downstream of loops are\n",
    "        preserved.\n",
    "\n",
    "        There are 2 things to track, what the current graph looks like and the stack of \n",
    "        nodes to run and their received prompts. Nodes on the stack have to check if they are a \n",
    "        root, or else they are not run yet. Root nodes on the stack are run in order, then\n",
    "        targets are added to the stack with their associated prompt. If the target is already\n",
    "        on the stack, simply give it the additional prompt.\n",
    "\n",
    "        If there are nodes, and all of the nodes have a source, this means that there is a loop \n",
    "        somewhere in the graph. We still want to run the flow, because recursive nodes are a \n",
    "        selling point. In this case, if ALL the nodes have a source, pick the most recently \n",
    "        created node and run it, sending its prompts and adding the new targets to the stack. We\n",
    "        do not update the graph now, instead simply running the node, then its targets in order.\n",
    "        This will continue running iterations, until a stop button is pressed.\n",
    "\n",
    "        The user will probably want to\n",
    "\n",
    "        We should create a stack, a list of dictionaries that look like this:\n",
    "        [{node_id: ____, sources_dict:{source_id:received_prompt = \"\" }}]\n",
    "        This forms a stack. Sources dict may or may not have multiple source_ids in it. Queue up\n",
    "        the next nodes to run based on what the targets of the node you just ran are. If\n",
    "        a node has multiple sources when it's run, combine those sources into one prompt\n",
    "        via concatenation. Received prompts are added first, with the LLMs actual text\n",
    "        entered into it added last. We may have to do prompt engineering to make sure\n",
    "        the LLM answers the prompt inputted into the box and not questions received as context,\n",
    "        but this is not preferred.\n",
    "        For bonus points, add an option to use dfs or bfs\n",
    "    '''\n",
    "    ### Should listen here to see if user hit the pause/stop button, and if they did pause or stop the execution of the code\n",
    "    listenForInput()\n",
    "\n",
    "    roots = findRoots(schema_dictionary)\n",
    "    nodes_to_send_outputs={}\n",
    "    #Base case: Check if schema dictionary has no roots\n",
    "    if len(roots) == 0:\n",
    "        if not schema_dictionary['edges']:\n",
    "            return(schema_dictionary)\n",
    "        # Other special case: we are looping \n",
    "        #this doesn't work, should make a function that follows the targets and returns False if ends up at a terminal branch and True if it \n",
    "        #comes back to itself\n",
    "        else:\n",
    "            if next_node_in_loop == \"start\":\n",
    "                for node in schema_dictionary['nodes']:\n",
    "                    term_list = checkTerminal(node['id'], schema_dictionary)\n",
    "                    print(term_list)\n",
    "                    if not checkTerminal(node['id'], schema_dictionary):\n",
    "                        \n",
    "                        current_node = node['id']\n",
    "                    else:\n",
    "                        print(\"Node just checked is terminal branch, skipping to find start node!\")\n",
    "            else:\n",
    "                current_node = next_node_in_loop\n",
    "                if checkBranch(current_node, schema_dictionary):\n",
    "                    print(\"Node just checked is a terminal branch, exiting the loop\")\n",
    "                    return(schema_dictionary)\n",
    "                \n",
    "            output = runLLM(current_node, schema_dictionary)\n",
    "            outputToChatbot(output)\n",
    "            for edge in next_schema_dictionary['edges']:\n",
    "                if edge['source'] == root:\n",
    "                    edge_id = edge['id']\n",
    "                    edge_ids_to_remove.append(edge_id)\n",
    "                    nodes_to_send_outputs[edge['target']] = output\n",
    "                    print(nodes_to_send_outputs)\n",
    "            for node_id in nodes_to_send_outputs:\n",
    "                runSchema(schema_dictionary, next_node_in_loop=node_id)\n",
    "                        \n",
    "\n",
    "        #If schema dictionary has no roots, check if empty. If empty, exit with some success code\n",
    "    \n",
    "        #if schema dictionary has no roots and is not empty, there is a loop. Listen for a stop\n",
    "        #signal from serverside, otherwise run schema dictionary in a loop \n",
    "\n",
    "    #Recursive case: Schema dictionary has roots. Get the outputs from the source node, make \n",
    "    #an updated schema dictionary where target nodes have the new outputs, and remove\n",
    "    #the edges that have already been checked\n",
    "\n",
    "    edge_ids_to_remove=[]\n",
    "    \n",
    "    next_schema_dictionary=schema_dictionary.copy()\n",
    "    for root in roots:\n",
    "        for edge in next_schema_dictionary['edges']:\n",
    "            if edge['source'] == root:\n",
    "                edge_id = edge['id']\n",
    "                edge_ids_to_remove.append(edge_id)\n",
    "                nodes_to_send_outputs[edge['target']] = \"\"\n",
    "                print(\"Printing the next nodes\")\n",
    "                print(nodes_to_send_outputs)\n",
    "                print(\"Printing the edges to be removed\")\n",
    "                print(edge_ids_to_remove)\n",
    "        output = runLLM(root, next_schema_dictionary)\n",
    "        ### SEND OUTPUT TO CHATBOT TO OUTPUT HERE ####\n",
    "        outputToChatbot(output)\n",
    "\n",
    "        for node_id in nodes_to_send_outputs.keys():\n",
    "            nodes_to_send_outputs[node_id] = output\n",
    "        updated_prompts_dict = updateNodePrompts(nodes_to_send_outputs, schema_dictionary)\n",
    "        next_schema_dictionary=removeEdgeIDs(edge_ids_to_remove, updated_prompts_dict)\n",
    "    print(next_schema_dictionary)\n",
    "    return(runSchema(next_schema_dictionary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running listenForInput\n",
      "removing from stack\n",
      "removing from stack\n",
      "removing from stack\n",
      "removing from stack\n",
      "removing from stack\n",
      "removing from stack\n",
      "{'Loop 1': True, 'Loop 2': True, 'Loop 3 ': True}\n",
      "Node just checked is terminal branch, skipping to find start node!\n",
      "{'Loop 1': True, 'Loop 2': True, 'Loop 3 ': True}\n",
      "Node just checked is terminal branch, skipping to find start node!\n",
      "{'Loop 1': True, 'Loop 2': True, 'Loop 3 ': True}\n",
      "Node just checked is terminal branch, skipping to find start node!\n"
     ]
    },
    {
     "ename": "UnboundLocalError",
     "evalue": "local variable 'current_node' referenced before assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[92], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m runSchema(schema_dictionary)\n",
      "Cell \u001b[0;32mIn[91], line 60\u001b[0m, in \u001b[0;36mrunSchema\u001b[0;34m(schema_dictionary, next_node_in_loop)\u001b[0m\n\u001b[1;32m     57\u001b[0m         \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mNode just checked is a terminal branch, exiting the loop\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     58\u001b[0m         \u001b[39mreturn\u001b[39;00m(schema_dictionary)\n\u001b[0;32m---> 60\u001b[0m output \u001b[39m=\u001b[39m runLLM(current_node, schema_dictionary)\n\u001b[1;32m     61\u001b[0m outputToChatbot(output)\n\u001b[1;32m     62\u001b[0m \u001b[39mfor\u001b[39;00m edge \u001b[39min\u001b[39;00m next_schema_dictionary[\u001b[39m'\u001b[39m\u001b[39medges\u001b[39m\u001b[39m'\u001b[39m]:\n",
      "\u001b[0;31mUnboundLocalError\u001b[0m: local variable 'current_node' referenced before assignment"
     ]
    }
   ],
   "source": [
    "runSchema(schema_dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
